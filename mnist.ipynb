{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Q1\n",
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "print(f\"Training Data Shape: {x_train.shape}, Labels: {y_train.shape}\")\n",
        "print(f\"Test Data Shape: {x_test.shape}, Labels: {y_test.shape}\")\n",
        "\n",
        "Interpretation:\n",
        "\n",
        "x_train.shape = (60000, 28, 28): 60,000 grayscale images, each 28x28 pixels.\n",
        "\n",
        "y_train.shape = (60000,): 60,000 labels (digits 0-9).\n",
        "\n",
        "x_test.shape = (10000, 28, 28): 10,000 test images, 28x28 pixels.\n",
        "\n",
        "y_test.shape = (10000,): 10,000 test labels.\n",
        "\n",
        "# Display 9 sample images with labels\n",
        "plt.figure(figsize=(8, 8))\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.imshow(x_train[i], cmap='gray')  # Show image in grayscale\n",
        "    plt.title(f\"Label: {y_train[i]}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "-- Helps confirm the dataset contains handwritten digits (0-9).\n",
        "\n",
        "#Check label distribution\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "# Count occurrences of each digit\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "\n",
        "# Plot distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x=unique, y=counts, palette=\"viridis\")\n",
        "plt.xlabel(\"Digit Label\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Distribution of Digit Labels in Training Data\")\n",
        "plt.show()\n",
        "\n",
        "# Check pixel stats\n",
        "\n",
        "print(f\"Pixel Value Range: Min = {x_train.min()}, Max = {x_train.max()}\")\n",
        "print(f\"Mean Pixel Value: {x_train.mean():.2f}, Standard Deviation: {x_train.std():.2f}\")\n",
        "\n",
        "\n",
        "# Step 2: Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values\n",
        "x_train = x_train.reshape(-1, 784)  # Flatten images\n",
        "x_test = x_test.reshape(-1, 784)\n",
        "\n",
        "# Step 3: Define a simple ANN model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(128, activation='relu', input_shape=(784,)),  # Hidden layer\n",
        "    keras.layers.Dense(10, activation='softmax')  # Output layer\n",
        "])\n",
        "\n",
        "# Step 4: Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Step 5: Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "# Step 6: Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "\n",
        "# Print the test accuracy\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "VbmPRY5somiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "x_train, x_test: Input images (28Ã—28 pixels, flattened to 784, normalized).\n",
        "\n",
        "y_train, y_test: Labels (digits 0-9).\n",
        "\n",
        "epochs=10: Trains for 10 iterations.\n",
        "\n",
        "optimizer='adam': Efficient weight updates for faster learning.\n",
        "\n",
        "activation='relu': Used in the hidden layer (128 neurons) for better training.\n",
        "\n",
        "activation='softmax': Converts outputs to probabilities (10 classes).\n",
        "\n",
        "loss='sparse_categorical_crossentropy': Handles integer labels for classification.\n",
        "\n",
        "validation_data=(x_test, y_test): Evaluates on test data during training.\n",
        "\n",
        "metrics=['accuracy']: Tracks classification accuracy."
      ],
      "metadata": {
        "id": "g3OKY1TP3zY9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Accuracy (97.97%): The model correctly predicts the digit 97.97% of the time, indicating strong performance.\n",
        "\n",
        "Loss (0.0845): This represents the model's error; a lower value suggests better optimization.\n",
        "\n",
        "Conclusion:\n",
        "The model is performing very well, with high accuracy and relatively low loss.\n",
        "\n",
        "The small loss value indicates that the model is well-trained and generalizes well to unseen data.\n",
        "\n",
        "No significant overfitting is observed."
      ],
      "metadata": {
        "id": "UwrFbvTftt7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create a model (with or without dropout)\n",
        "def create_model(use_dropout=False):\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Dense(128, activation='relu', input_shape=(784,)))  # Hidden layer\n",
        "    if use_dropout:\n",
        "        model.add(keras.layers.Dropout(0.2))  # Apply Dropout if specified\n",
        "    model.add(keras.layers.Dense(10, activation='softmax'))  # Output layer\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Train the model WITHOUT dropout\n",
        "model_no_dropout = create_model(use_dropout=False)\n",
        "history_no_dropout = model_no_dropout.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "# Train the model WITH dropout\n",
        "model_with_dropout = create_model(use_dropout=True)\n",
        "history_with_dropout = model_with_dropout.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate both models on test data\n",
        "test_loss_no_dropout, test_acc_no_dropout = model_no_dropout.evaluate(x_test, y_test, verbose=2)\n",
        "test_loss_with_dropout, test_acc_with_dropout = model_with_dropout.evaluate(x_test, y_test, verbose=2)\n",
        "\n",
        "# Print comparison of test accuracy\n",
        "print(f\"Test Accuracy WITHOUT Dropout: {test_acc_no_dropout:.4f}\")\n",
        "print(f\"Test Accuracy WITH Dropout (0.2): {test_acc_with_dropout:.4f}\")\n",
        "\n",
        "# Plot accuracy comparison\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Accuracy comparison plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_no_dropout.history['val_accuracy'], label='No Dropout')\n",
        "plt.plot(history_with_dropout.history['val_accuracy'], label='With Dropout')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Test Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Test Accuracy Comparison')\n",
        "\n",
        "# Loss comparison plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_no_dropout.history['val_loss'], label='No Dropout')\n",
        "plt.plot(history_with_dropout.history['val_loss'], label='With Dropout')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Test Loss')\n",
        "plt.legend()\n",
        "plt.title('Test Loss Comparison')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ORqcOG4xpL2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Accuracy:\n",
        "\n",
        "The model with dropout (98.03%) performs slightly better than the model without dropout (97.91%).\n",
        "\n",
        "Dropout helps prevent overfitting, which may have improved generalization.\n",
        "\n",
        "Loss:\n",
        "\n",
        "The lower loss (0.0681) for the dropout model indicates better optimization.\n",
        "\n",
        "A higher loss (0.0739) in the non-dropout model suggests possible overfitting."
      ],
      "metadata": {
        "id": "EmyoIgiasDc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Q1 2 - b\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import joblib\n",
        "\n",
        "# Step 1: Train the model (using previous trained model)\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(128, activation='relu', input_shape=(784,)),  # Hidden layer\n",
        "    keras.layers.Dense(10, activation='softmax')  # Output layer\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "# Step 2: Make predictions\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels\n",
        "\n",
        "# Step 3: Compute accuracy, precision, recall, and F1-score\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
        "recall = recall_score(y_test, y_pred_classes, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "\n",
        "# Print the metrics in a structured format\n",
        "print(\"=\"*40)\n",
        "print(\"|   Metric      |   Value    |\")\n",
        "print(\"=\"*40)\n",
        "print(f\"| Accuracy      |   {accuracy:.4f}   |\")\n",
        "print(f\"| Precision     |   {precision:.4f}   |\")\n",
        "print(f\"| Recall        |   {recall:.4f}   |\")\n",
        "print(f\"| F1 Score      |   {f1:.4f}   |\")\n",
        "print(\"=\"*40)"
      ],
      "metadata": {
        "id": "e2bjHtxhpUU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the metrics in a structured format\n",
        "print(\"=\"*40)\n",
        "print(\"|   Metric      |   Value    |\")\n",
        "print(\"=\"*40)\n",
        "print(f\"| Accuracy      |   {accuracy:.4f}   |\")\n",
        "print(f\"| Precision     |   {precision:.4f}   |\")\n",
        "print(f\"| Recall        |   {recall:.4f}   |\")\n",
        "print(f\"| F1 Score      |   {f1:.4f}   |\")\n",
        "print(\"=\"*40)"
      ],
      "metadata": {
        "id": "vIKrdi9Rs1Rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O mnist.ipynb https://raw.githubusercontent.com/gautami2003/abc/main/mnist.ipynb"
      ],
      "metadata": {
        "id": "sep-v_Jf4NOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy (97.93%): The model correctly predicts the digit in 97.93% of test cases.\n",
        "\n",
        "Precision (97.94%): When the model predicts a digit, 97.94% of those predictions are correct.\n",
        "\n",
        "Recall (97.93%): The model correctly identifies 97.93% of all actual digits.\n",
        "\n",
        "F1 Score (97.93%): A balanced measure confirming high precision and recal"
      ],
      "metadata": {
        "id": "udZOA6Zbrpzx"
      }
    }
  ]
}