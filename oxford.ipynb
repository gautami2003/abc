{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Importing Libraries\n",
        "import os\n",
        "import glob\n",
        "import datetime\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from keras.models import model_from_json\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.regularizers import L2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense, LeakyReLU, BatchNormalization, ReLU\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "# Set TensorFlow version\n",
        "tf.__version__\n",
        "\n",
        "# Constants for image size, data split, and random state\n",
        "IMAGE_SIZE = (128, 128)\n",
        "RANDOM_STATE = 7\n",
        "TRAIN_SIZE, VAL_SIZE, TEST_SIZE = 0.8, 0.1, 0.1\n",
        "import os\n",
        "import urllib.request\n",
        "import tarfile\n",
        "\n",
        "# Define URL and directory\n",
        "DATA_URL = \"https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\"\n",
        "DATA_DIR = \"/content/oxford_pets_data\"\n",
        "FILE_PATH = os.path.join(DATA_DIR, \"images.tar.gz\")\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(DATA_DIR):\n",
        "    os.makedirs(DATA_DIR)\n",
        "\n",
        "# Download the dataset if not already downloaded\n",
        "if not os.path.exists(FILE_PATH):\n",
        "    print(\"Downloading dataset...\")\n",
        "    urllib.request.urlretrieve(DATA_URL, FILE_PATH)\n",
        "    print(\"Download complete!\")\n",
        "\n",
        "# Extract the dataset\n",
        "print(\"Extracting dataset...\")\n",
        "with tarfile.open(FILE_PATH, 'r:gz') as tar_ref:\n",
        "    tar_ref.extractall(DATA_DIR)\n",
        "print(\"Dataset downloaded and extracted!\")\n",
        "\n",
        "# Verify the dataset is downloaded\n",
        "BASE_PATH = os.path.join(DATA_DIR, \"images\")  # Adjust this if necessary\n",
        "imageNames = [os.path.basename(file) for file in glob.glob(os.path.join(BASE_PATH, '*.jpg'))]\n",
        "print(f\"Total number of image files: {len(imageNames)}\")\n",
        "\n",
        "# Reading target label from filenames\n",
        "labels = [' '.join(name.split('_')[:-1]) for name in imageNames ]\n",
        "print(f\"Total number of unique labels: {len(np.unique(labels))}\")\n",
        "\n",
        "# Label Encoding and lookup dictionary\n",
        "labelEncDict = {name: ind for ind, name in enumerate(np.unique(labels))}\n",
        "for k, v in labelEncDict.items():\n",
        "    print(f\"{k:32} : {v}\")\n",
        "\n",
        "# Reverse lookup dictionary\n",
        "labelDecDict = {ind: name for name, ind in labelEncDict.items()}\n",
        "\n",
        "# Loading the image data\n",
        "imageData = []\n",
        "for name in tqdm(imageNames, desc = 'Loading image data', unit = ' images'):\n",
        "    img = load_img(os.path.join(BASE_PATH, name))\n",
        "    img = tf.image.resize_with_pad(img_to_array(img, dtype = 'uint8'), *IMAGE_SIZE).numpy().astype('uint8')\n",
        "    imageData.append(img)\n",
        "\n",
        "imageData = np.array(imageData)\n",
        "imageData.shape\n",
        "\n",
        "# Encoding Target labels\n",
        "labelsEncoded = list(map(lambda x : labelEncDict.get(x), labels))\n",
        "for i, l in zip(imageNames[::1000], labelsEncoded[::1000]):\n",
        "    print(f\"{i:32}\\t{labelDecDict[l]:32}\\t{l}\")\n",
        "\n",
        "# Split data and labels into Train, Test, and Validation sets\n",
        "X_tv, X_test, y_tv, y_test = train_test_split(\n",
        "    imageData,\n",
        "    labelsEncoded,\n",
        "    test_size = TEST_SIZE,\n",
        "    random_state = RANDOM_STATE,\n",
        "    stratify = labelsEncoded\n",
        ")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_tv,\n",
        "    y_tv,\n",
        "    test_size = VAL_SIZE,\n",
        "    random_state = RANDOM_STATE,\n",
        "    stratify = y_tv\n",
        ")\n",
        "\n",
        "print(f'Training Data: {X_train.shape}')\n",
        "print(f'Training Labels: {len(y_train)}')\n",
        "print(f'\\nValidation Data: {X_val.shape}')\n",
        "print(f'Validation Labels: {len(y_val)}')\n",
        "print(f'\\nTesting Data: {X_test.shape}')\n",
        "print(f'Testing Labels: {len(y_test)}')\n",
        "\n",
        "# Image Data Generator for training, validation, and test data\n",
        "train_gen = ImageDataGenerator(rescale = 1./255,\n",
        "                               rotation_range = 30,\n",
        "                               width_shift_range = 0.1,\n",
        "                               height_shift_range = 0.1,\n",
        "                               shear_range = 0.1,\n",
        "                               zoom_range = 0.1,\n",
        "                               horizontal_flip = True,\n",
        "                               fill_mode = 'nearest')\n",
        "train_data = train_gen.flow(x = X_train, y = y_train, batch_size = 32, shuffle = True)\n",
        "\n",
        "val_gen = ImageDataGenerator(rescale = 1./255)\n",
        "val_data = val_gen.flow(x = X_val, y = y_val, batch_size = 32, shuffle = True)\n",
        "\n",
        "test_gen = ImageDataGenerator(rescale = 1./255)\n",
        "test_data = test_gen.flow(x = X_test, y = y_test, batch_size = 32)\n",
        "\n",
        "# CNN Model Creation\n",
        "model = Sequential([\n",
        "    Conv2D(32, 5, padding = 'same', input_shape = (*IMAGE_SIZE, 3)),\n",
        "    Conv2D(32, 5, padding = 'same', activation = LeakyReLU(alpha = 0.5)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 4, padding = 'same'),\n",
        "    Conv2D(32, 4, padding = 'same', activation = LeakyReLU(alpha = 0.5)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 4, padding = 'same'),\n",
        "    Conv2D(64, 4, padding = 'same', activation = LeakyReLU(alpha = 0.5)),\n",
        "    MaxPooling2D(),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(64, 3, padding = 'same'),\n",
        "    Conv2D(64, 3, padding = 'same', activation = LeakyReLU(alpha = 0.5)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding = 'same'),\n",
        "    Conv2D(128, 3, padding = 'same', activation = LeakyReLU(alpha = 0.5)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 2, padding = 'same'),\n",
        "    Conv2D(128, 2, padding = 'same', activation = LeakyReLU(alpha = 0.5)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(256, 2, padding = 'same'),\n",
        "    Conv2D(256, 2, padding = 'same', activation = LeakyReLU(alpha = 0.5)),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "    Dense(512, activation = 'sigmoid'),\n",
        "    Dropout(0.2),\n",
        "    Dense(256, activation = 'sigmoid'),\n",
        "    Dropout(0.1),\n",
        "    Dense(len(labelEncDict), activation = 'softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer = Adam(learning_rate=0.0001),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics = ['sparse_categorical_accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_data, validation_data = val_data, epochs = 50, verbose = 1)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_data, verbose = 0)\n",
        "print(f\"Loss on Testing data: {test_loss}\")\n",
        "print(f\"Accuracy on Testing data: {test_acc}\")\n",
        "\n",
        "# Saving the trained model\n",
        "model.save('/content/oxford_pets_model')\n",
        "\n",
        "# Load Saved Model\n",
        "saved_model = tf.keras.models.load_model('/content/oxford_pets_model')\n",
        "\n",
        "# Evaluate the loaded model\n",
        "sm_test_loss, sm_test_acc = saved_model.evaluate(test_data, verbose = 0)\n",
        "print(f\"Loss on Testing data (loaded model): {sm_test_loss}\")\n",
        "print(f\"Accuracy on Testing data (loaded model): {sm_test_acc}\")"
      ],
      "metadata": {
        "id": "g2Rm7IhGL_lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Download & Extract Dataset\n",
        "Downloads the Oxford-IIIT Pet Dataset (images.tar.gz).\n",
        "\n",
        "Extracts image files to oxford_pets_data/images/.\n",
        "\n",
        "2. Preprocess Data\n",
        "Reads image filenames and extracts class labels.\n",
        "\n",
        "Encodes labels into numerical values.\n",
        "\n",
        "Resizes images to (256, 256).\n",
        "\n",
        "Splits data into Train (80%), Validation (10%), and Test (10%).\n",
        "\n",
        "3. Data Augmentation\n",
        "Uses ImageDataGenerator to apply transformations such as rotation, zoom, and flips to training data.\n",
        "\n",
        "4. Build CNN Model\n",
        "A deep Convolutional Neural Network (CNN) with:\n",
        "\n",
        "Multiple Conv2D layers for feature extraction.\n",
        "\n",
        "LeakyReLU activation to avoid vanishing gradients.\n",
        "\n",
        "MaxPooling2D layers to reduce spatial dimensions.\n",
        "\n",
        "BatchNormalization and Dropout for regularization.\n",
        "\n",
        "Fully connected (Dense) layers with softmax activation for classification.\n",
        "\n",
        "5. Compile & Train Model\n",
        "Uses the Adam optimizer (lr=0.0001) with sparse_categorical_crossentropy loss.\n",
        "\n",
        "Trains for 50 epochs, tracking accuracy and loss.\n",
        "\n",
        "6. Evaluate & Save Model\n",
        "Evaluates the model on test data.\n",
        "\n",
        "Saves the trained model as oxford_pets_model.\n",
        "\n",
        "Loads the saved model and re-evaluates its performance."
      ],
      "metadata": {
        "id": "P68rzrlIToBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Constants\n",
        "IMAGE_SIZE = (128, 128)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50\n",
        "RANDOM_STATE = 7\n",
        "DATA_DIR = \"./oxford_pets_data\"\n",
        "BASE_PATH = os.path.join(DATA_DIR, \"images\")\n",
        "\n",
        "# Load images and labels\n",
        "image_names = [os.path.basename(file) for file in glob.glob(os.path.join(BASE_PATH, '*.jpg'))]\n",
        "labels = [' '.join(name.split('_')[:-1]) for name in image_names]\n",
        "label_enc_dict = {name: ind for ind, name in enumerate(np.unique(labels))}\n",
        "label_dec_dict = {ind: name for name, ind in label_enc_dict.items()}\n",
        "\n",
        "# Process images\n",
        "image_data = []\n",
        "for name in tqdm(image_names, desc='Loading images'):\n",
        "    img = load_img(os.path.join(BASE_PATH, name), target_size=IMAGE_SIZE)\n",
        "    img = img_to_array(img) / 255.0  # Normalize\n",
        "    image_data.append(img)\n",
        "\n",
        "image_data = np.array(image_data)\n",
        "labels_encoded = np.array([label_enc_dict[label] for label in labels])\n",
        "\n",
        "# Split data\n",
        "X_tv, X_test, y_tv, y_test = train_test_split(image_data, labels_encoded, test_size=0.1, stratify=labels_encoded, random_state=RANDOM_STATE)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_tv, y_tv, test_size=0.1, stratify=y_tv, random_state=RANDOM_STATE)\n",
        "\n",
        "# Data augmentation\n",
        "train_gen = ImageDataGenerator(rotation_range=30, horizontal_flip=True)\n",
        "train_data = train_gen.flow(X_train, y_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_data = ImageDataGenerator().flow(X_val, y_val, batch_size=BATCH_SIZE)\n",
        "test_data = ImageDataGenerator().flow(X_test, y_test, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Model using MobileNetV2 as feature extractor\n",
        "base_model = MobileNetV2(input_shape=(*IMAGE_SIZE, 3), include_top=False, weights='imagenet')\n",
        "base_model.trainable = False\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(len(label_enc_dict), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Training\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "history = model.fit(train_data, validation_data=val_data, epochs=EPOCHS, callbacks=[early_stopping])\n",
        "\n",
        "# Plot training history\n",
        "def plot_history(history):\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    ax[0].plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    ax[0].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    ax[0].set_title('Accuracy')\n",
        "    ax[0].legend()\n",
        "\n",
        "    ax[1].plot(history.history['loss'], label='Train Loss')\n",
        "    ax[1].plot(history.history['val_loss'], label='Validation Loss')\n",
        "    ax[1].set_title('Loss')\n",
        "    ax[1].legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history)\n",
        "\n",
        "# Evaluate model\n",
        "test_loss, test_acc = model.evaluate(test_data)\n",
        "print(f'Test Accuracy: {test_acc}')\n",
        "\n",
        "# Confusion Matrix\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(label_enc_dict.keys()))\n",
        "disp.plot(figsize=(12, 12))\n",
        "plt.show()\n",
        "\n",
        "# Save model\n",
        "model.save('oxford_pets_model.h5')\n"
      ],
      "metadata": {
        "id": "ZfRUgbZpSiH0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}