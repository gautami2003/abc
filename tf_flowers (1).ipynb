{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_t5yK0v4HJy"
      },
      "outputs": [],
      "source": [
        "#Step 1: Import Required Libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load and Explore the Dataset\n",
        "# The tf_flowers dataset contains 3,670 images of flowers belonging to 5 classes:Daisy.Dandelion\n",
        "\n",
        "# Roses\n",
        "\n",
        "# Sunflowers\n",
        "# Tulips\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import shutil\n",
        "\n",
        "# The dataset URL containing the flower images\n",
        "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "\n",
        "# Download and extract the dataset\n",
        "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\n",
        "\n",
        "# Path to the extracted folder\n",
        "data_dir = os.path.join(data_dir, 'flower_photos')\n",
        "\n",
        "# List of flower classes\n",
        "classes = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
        "\n",
        "# Create subdirectories for each class\n",
        "for flower_class in classes:\n",
        "    os.makedirs(os.path.join(data_dir, flower_class), exist_ok=True)\n",
        "\n",
        "# Get all files in the directory\n",
        "all_files = os.listdir(data_dir)\n",
        "\n",
        "# Move the image files into respective class directories\n",
        "for file in all_files:\n",
        "    file_path = os.path.join(data_dir, file)\n",
        "\n",
        "    # Skip directories (we only want to move image files)\n",
        "    if os.path.isdir(file_path):\n",
        "        continue\n",
        "\n",
        "    # Logic to assign classes - here, using the filename to decide the class (customize this part as needed)\n",
        "    for flower_class in classes:\n",
        "        if flower_class in file.lower():  # This is just an example, adjust as per your logic\n",
        "            destination_dir = os.path.join(data_dir, flower_class)\n",
        "            shutil.move(file_path, os.path.join(destination_dir, file))\n",
        "\n",
        "# Now that the images are organized, load the dataset as before\n",
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180\n",
        "\n",
        "# Load the training dataset (80% for training, 20% for validation)\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Load the validation dataset\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Get class names (flower categories)\n",
        "class_names = train_ds.class_names\n",
        "print(\"Class names:\", class_names)"
      ],
      "metadata": {
        "id": "u_9H2mm14gcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 3: Visualize Sample Images\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")\n",
        "plt.show()\n",
        "#Output: Displays 9 random flower images with labels."
      ],
      "metadata": {
        "id": "76xCJIys7ND3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import shutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# The dataset URL containing the flower images\n",
        "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "\n",
        "# Download and extract the dataset\n",
        "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\n",
        "\n",
        "# Path to the extracted folder\n",
        "data_dir = os.path.join(data_dir, 'flower_photos')\n",
        "\n",
        "# List of flower classes\n",
        "classes = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
        "\n",
        "# Create subdirectories for each class\n",
        "for flower_class in classes:\n",
        "    os.makedirs(os.path.join(data_dir, flower_class), exist_ok=True)\n",
        "\n",
        "# Get all files in the directory\n",
        "all_files = os.listdir(data_dir)\n",
        "\n",
        "# Move the image files into respective class directories\n",
        "for file in all_files:\n",
        "    file_path = os.path.join(data_dir, file)\n",
        "\n",
        "    # Skip directories (we only want to move image files)\n",
        "    if os.path.isdir(file_path):\n",
        "        continue\n",
        "\n",
        "    # Logic to assign classes - here, using the filename to decide the class (customize this part as needed)\n",
        "    for flower_class in classes:\n",
        "        if flower_class in file.lower():  # This is just an example, adjust as per your logic\n",
        "            destination_dir = os.path.join(data_dir, flower_class)\n",
        "            shutil.move(file_path, os.path.join(destination_dir, file))\n",
        "\n",
        "# Step 2: Data Augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip('horizontal'),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.2),\n",
        "])\n",
        "\n",
        "# Step 3: Preprocess Data (Normalization & Caching)\n",
        "# Normalize pixel values to [0,1]\n",
        "normalization_layer = layers.Rescaling(1./255)\n",
        "\n",
        "batch_size = 64  # Increased batch size for faster training\n",
        "img_height = 160  # Reduced image size for faster processing\n",
        "img_width = 160\n",
        "\n",
        "# Load the training dataset (80% for training, 20% for validation)\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Load the validation dataset\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Apply augmentation and normalization to datasets\n",
        "train_ds = train_ds.map(lambda x, y: (data_augmentation(x), y))\n",
        "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "# Cache and prefetch for better performance\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "# Step 4: Use MobileNetV2 as a Pre-trained Model\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=(img_height, img_width, 3),\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "\n",
        "# Freeze base model layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Build the model by adding custom layers\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(5, activation='softmax')  # 5 flower classes\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Step 5: Learning Rate Scheduler\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: 1e-4 * 10**(epoch / 10))\n",
        "\n",
        "# Step 6: Train the Model\n",
        "epochs = 5  # Reduced number of epochs for faster experimentation\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=len(train_ds),\n",
        "    validation_steps=len(val_ds),\n",
        "    callbacks=[lr_scheduler]\n",
        ")\n",
        "\n",
        "# Step 7: Evaluate Model Performance\n",
        "\n",
        "# (A) Plot Training vs Validation Accuracy/Loss\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy over Epochs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss over Epochs')\n",
        "plt.show()\n",
        "\n",
        "# (B) Generate Classification Report\n",
        "# Get true labels and predictions\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for images, labels in val_ds:\n",
        "    y_true.extend(labels.numpy())\n",
        "    y_pred.extend(np.argmax(model.predict(images), axis=1))\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=classes))\n",
        "\n",
        "# (C) Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Step 8: Save and Reload the Model\n",
        "# Save the model\n",
        "model.save('flower_classifier.h5')\n",
        "\n",
        "# Load the model\n",
        "loaded_model = tf.keras.models.load_model('flower_classifier.h5')\n",
        "\n",
        "# Verify loaded model\n",
        "_, loaded_acc = loaded_model.evaluate(val_ds, verbose=0)\n",
        "print(f\"\\nLoaded Model Validation Accuracy: {loaded_acc:.4f}\")\n",
        "\n",
        "# Step 9: Prediction Function\n",
        "predict_flower = lambda img_path: ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips'][\n",
        "    tf.keras.models.load_model('flower_classifier.h5')\n",
        "    .predict(image.img_to_array(image.load_img(img_path, target_size=(img_height, img_width)))\n",
        "    .reshape(1, img_height, img_width, 3) / 255.).argmax()]\n",
        "\n"
      ],
      "metadata": {
        "id": "fVSrM9Qb-BlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage (returns flower name directly)\n",
        "print(predict_flower(\"/content/tulip.jpg\"))"
      ],
      "metadata": {
        "id": "b0Kcq0SqD1aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-- Code Explaination\n",
        "\n",
        "Dataset Preparation:\n",
        "\n",
        "Downloads a flower dataset and extracts it.\n",
        "\n",
        "Organizes images into class-specific directories (daisy, dandelion, roses, sunflowers, tulips) based on filenames.\n",
        "\n",
        "Data Augmentation:\n",
        "\n",
        "Uses RandomFlip, RandomRotation, and RandomZoom to artificially augment the training data for better model generalization.\n",
        "\n",
        "Data Preprocessing:\n",
        "\n",
        "Rescales the images to a [0, 1] range for normalization.\n",
        "\n",
        "Loads training and validation datasets from the directories, applying augmentation and normalization.\n",
        "\n",
        "Caches and prefetches data for faster performance.\n",
        "\n",
        "Model Building:\n",
        "\n",
        "Uses MobileNetV2 as a pre-trained model (without the top layer) for transfer learning.\n",
        "\n",
        "Adds custom layers: GlobalAveragePooling2D, Dense layers, and Dropout.\n",
        "\n",
        "Compiles the model with Adam optimizer and sparse_categorical_crossentropy loss.\n",
        "\n",
        "Training:\n",
        "\n",
        "Trains the model for 5 epochs with a learning rate scheduler.\n",
        "\n",
        "Displays accuracy and loss plots during training.\n",
        "\n",
        "Evaluation:\n",
        "\n",
        "Generates a classification report and confusion matrix based on validation data.\n",
        "\n",
        "Model Saving and Loading:\n",
        "\n",
        "Saves the trained model to a file and reloads it for evaluation.\n",
        "\n",
        "Prediction:\n",
        "\n",
        "Defines a function to predict the flower class for an input image."
      ],
      "metadata": {
        "id": "R8xsEn0JE66u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-- Output Explaination\n",
        "\n",
        "Dataset Download & Processing:\n",
        "\n",
        "Flower dataset (3670 images) is downloaded and split into:\n",
        "\n",
        "Training set: 2936 images (80%)\n",
        "\n",
        "Validation set: 734 images (20%)\n",
        "\n",
        "Pre-trained MobileNetV2 weights are also downloaded.\n",
        "\n",
        "Model Summary:\n",
        "\n",
        "Uses MobileNetV2 as a feature extractor (frozen layers).\n",
        "\n",
        "Additional layers:\n",
        "\n",
        "Global Average Pooling → Reduces feature map size.\n",
        "\n",
        "Dense(128, relu) → Intermediate layer.\n",
        "\n",
        "Dropout(0.5) → Prevents overfitting.\n",
        "\n",
        "Dense(5, softmax) → Output layer for 5 classes.\n",
        "\n",
        "Total parameters: 2.42M (mostly from MobileNetV2).\n",
        "\n",
        "Training Progress (5 Epochs):\n",
        "\n",
        "Epoch 1:\n",
        "\n",
        "Training accuracy 28%, Validation accuracy 62%.\n",
        "\n",
        "Epoch 5:\n",
        "\n",
        "Training accuracy 77.8%, Validation accuracy 82.3%.\n",
        "\n",
        "Loss decreases steadily, showing model improvement.\n",
        "\n",
        "Evaluation Results:\n",
        "\n",
        "Classification Report:\n",
        "\n",
        "Overall accuracy: 82%.\n",
        "\n",
        "Precision, recall, and F1-score are highest for sunflowers (87%) and lowest for roses (79%).\n",
        "\n",
        "Dandelions have the best recall (90%), meaning most were correctly identified.\n",
        "\n",
        "Confusion Matrix (Interpreted in Report):\n",
        "\n",
        "Some misclassifications occur, especially between similar flowers.\n",
        "\n",
        "Daisies (71% recall) are often misclassified, possibly due to similarity with dandelions."
      ],
      "metadata": {
        "id": "ZE-LDsmZFPFw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UCh5qDZoE-iy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}